---
title: "An Introduction to the Tidyverse"
author: "Joseph Walker"
date: "`r Sys.Date()`"
output: 
  html_document: 
    highlight: pygments
    theme: readable
    toc: yes
    toc_float: yes
---
# Introduction

Welcome to the tidyverse tutorial. The information below provides an introduction to the suite of packages contained in the tidyverse that are useful for programming in R. The tidyverse was created by Hadley Wickham, a prominent R developer and statistician. 

Before we begin, here are some useful resources to learn more about R and the topics in this tutorial.

The tidyverse site which contains detailed information about each package: http://tidyverse.org/

The awesome *R for Data Science* book, free and in full: http://r4ds.had.co.nz/

For quick references to useful packages and functions, go to Help --> Cheatsheets in the R studio menu bar. You can also find them here: https://www.rstudio.com/resources/cheatsheets/


```{r setup, include=FALSE, warning = FALSE, message = FALSE}
knitr::opts_chunk$set(echo = TRUE, warning = FALSE, message = FALSE)
```

Let's start by installing the tidyverse:

`install.packages("tidyverse")`

As with all packages, you have to load it before the functions are available to use:

```{r load tidyverse, warning = FALSE, message=TRUE}
library(tidyverse)
```

It is important to note that only the **core** packages are loaded.  Other tidyverse packages need to be loaded explicitly.

We can see all packages that are part of the tidyverse with the following code:

```{r all tidverse packages}
tidyverse_packages(include_self = TRUE)
```

## A Model for Data Analysis
So where to start?

One of the key concepts in R for Data Science is understanding the model used to approach a data science project.  

We can think about this model more broadly to fit the scope of any problem we have or data we seek to analyze:  

![](model.png)  

So then, let's dive into the packages as we follow along the steps of our model.  

---


# Import {.tabset .tabset-pills}

In order to work with your data in R, you have to import it!

## readr

* functions tend to be faster (~10x)
* readr functions produce *tibbles* and don't convert character vectors to factors *(more on that later)*
* reproducible: some base R functions inherit behavior from your OS and environment variables and may not work if you share with others

Useful for reading and writing csv, tsv, tables, lines(of a file or string).

```{r readr}

write_csv(x = mtcars, path = "mtcars_data.csv") # writes to current working directory unless otherwise specified in the path argument

read_csv(file = "mtcars_data.csv", col_names = TRUE)
```

---

## readxl

* Must be loaded explicitly  
* Useful for .xls & .xlsx files  

---

## jsonlite

* for pasing json files
* `tidyjson` contains jsonlite functionality and is a useful package that uses 'tidy' principles for turning json data into useful tables.

---

## other types of data

**Haven** for SPSS, Stata and SAS files  
**xml2** for parsing xml  
**rvest** for web scraping  

---

# Data Wrangling

The bread and butter of data analysis involves the next two steps of the model: tidying and transformation, often called **data wrangling**.

## Tidy {.tabset .tabset-fade .tabset-pills #anchor}

Packages in the tidyverse are designed to work together to incorporate *tidy* principles.

There are three rules which make a dataset *tidy*:  

* Each variable must have its own column 
* Each observation must have its own row 
* Each value must have its own cell 

### Forcats {.tabset .tabset-fade .tabset-pills}

If you've ever dealt with factors using base R, you know that it can be a challenge. Thankfully, the `forcats` package has a multitude of functions useful for handling factors efficiently.

**We need to load the `forcats` package explicitly as it is not part of the core tidyverse packages.**

```{r load forcats}
library(forcats)
```

#### Factor Recode
One useful function of `forcats` is `fct_recode`. This allows you to change the levels (or name/identity) of a factor. Here's an example:

```{r change level values}
#Let's use the airquality data set that comes pre-installed in R
glimpse(airquality)

#The month column is data type integer, let's change it to a factor 
airquality$Month <- factor(airquality$Month)

levels(airquality$Month)

#Let's rename the months using the fct_recode function. 
airquality$Month <- fct_recode(airquality$Month, May = '5', June = '6', July = '7', Aug = '8', Sept = '9')
glimpse(airquality$Month)

ggplot(airquality, aes(Month, Temp)) +
  geom_boxplot(aes(fill = Month)) +
  ggtitle(label = "Daily Temperatures Aggregated by Month")
```

---

#### Factor Reverse
If you just want to reverse the order, there's the `fct_rev` function. You can even use it in line when defining your aesthetics in ggplot like so:
```{r reverse the order}

ggplot(airquality, aes(fct_rev(Month), Temp)) +
  geom_boxplot(aes(fill = Month)) +
  labs(x = "Month") +
  ggtitle(label = "Our plot now has the x-axis in reverse order")
```

---

#### Factor Relevel

Another useful function is `fct_relevel`. This function allows us to change any number of levels to any position.

```{r change level position}
airquality$Month <- fct_relevel(airquality$Month, 'Sept', 'July', 'May', 'Aug', 'June')

levels(airquality$Month)

# This may not seem useful at first, but when you need to visualize your data in a particular way, the fct_relevel function is extremely useful...

ggplot(airquality, aes(Month, Temp)) +
  geom_boxplot(aes(fill = Month)) +
  ggtitle(label = "Notice how the order of the level 'Month' has changed")
```

---

#### Factor Reorder

And finally, it is often useful to reorder the factor in a way that is useful for visualization. For this, we can use the `fct_reorder` function.

For this example, let's use the mtcars data set:
```{r fct_reorder setup}
mtcars$model <- row.names(mtcars)

glimpse(mtcars)

mtcars$model <- factor(mtcars$model)

ggplot(mtcars, aes(mpg, model)) +
  geom_point() +
  ggtitle(label = "MPG vs. Car Model")

```

It's difficult to make comparisons when the data is scattered. But we're in luck! We can use the `fct_reorder` function to clean it up.

```{r fct_reorder}
#fct_reorder takes three arguments: f = factor you want to reorder, x = the variable in which the order will be based upon, and optionally fun (a function to  be used if there are multiple values of x for each value of f.) Here we focus on only the first two arguments.

ggplot(mtcars, aes(mpg, fct_reorder(f = model, x = mpg))) +
  geom_point() +
  labs(y = "model") +
  ggtitle(label = "We can make better comparison by reordering the levels based on the mpg values!") +
  theme(plot.title = element_text(size = 10, face = 'bold'))

```

---

### Lubridate

The **Lubridate** package makes working with dates and times a breeze.

Lubrdiate must be loaded explicitly as it is not part of the core tidyverse suite of packages.

```{r load lubridate}
library(lubridate)
```

```{r lubridate}
#today
today()


year <- 2014
month <- 1:12
day <- 1:12

my.dates <- data.frame(year = year,
                   month = month,
                   day = day)

# make_datetime
my.dates$date <- make_datetime(year, month, day)

glimpse(my.dates)

#take dates as strings and convert them to posixct dates using parse_date_time
birthdays <- c("02-23-1955", "09-12-1958", "06-25-1987")

birthdays <- parse_date_time(x = birthdays, orders = "%m-%d-%Y")
lubridate::month(x = birthdays, label = TRUE , abbr = TRUE)

birthdays %>% month(label = TRUE, abbr = FALSE)

ymd(birthdays)

day(birthdays)

#durations
dseconds(60)
dminutes(5)
dhours(c(24, 96))
ddays(3:5)

span <- interval(start = birthdays[1], end = birthdays[3])
span

dur <- as.duration(span)

as.numeric(dur, "days")
```
---

### Magrittr

At the heart of R coding using tidy principles is the piping function **`%>%`**. This useful tools allows you to string together operations in an intuitive way. The piping operator was born from the magrittr package, self described in the vignette as:

> The magrittr (to be pronounced with a sophisticated french accent) is a package with two aims: to decrease development time and to improve readability and maintainability of code. Or even shortr: to make your code smokin' (puff puff)!

The pipe operator, along with many tidyverse functions uses Non-Standard Evaluation (NSE). This concept is essential to the core of R programming. All you need to know about it for now is that it dramatically reduces the amount of typing. 

For more on NSE: https://cran.r-project.org/web/packages/dplyr/vignettes/nse.html

---

### Tibble

A tibble is simply the tidyverse version of a dataframe. It is the strucutural foundation of your data. Tibbles maintain the elements of a dataframe that have stood the test of time and drop those which have proven to be frustrating.

Tibbles: 
* never change an input's type (strings aren't coerced to factors)
* never adjusts the names of variables
* never adds row.names (mtcars example)

```{r tibble example}

"assay value" <- c(2.3, 1.8, 2.1, .7, 1.6)
"y number" <- c("Y29438", "Y22322", "Y27011", "Y16148", "Y21900") 


glimpse(data.frame(`assay value`, `y number`))

glimpse(tibble(`assay value`, `y number`))
glimpse(row.names(tibble(`assay value`, `y number`)))

glimpse(row.names(mtcars))

rownames_to_column(df = mtcars, var = "car_model")
```

---

### Tidyr {.tabset .tabset-fade .tabset-pills}

**The tidyr package is useful for visualizing and reshaping data.**

#### Nest

Nesting can be performed for many different purposes. One of the most useful I've found is for linear modeling.


```{r nest function}

nested_iris <- iris %>% nest(-Species)
tbl_df(nested_iris)

model <- function(df){lm(Sepal.Length ~ ., data = df)}

nested_iris <- nested_iris %>% 
  mutate(model = map(data, model))

tbl_df(nested_iris)

```

---

#### Syntax

The following functions are basic but essential to the foundation of the tidyverse.

`tbl_df` makes it easier to take a look at a data frame. R displays only the info. that fits on the screen. By default a tibble utilizes the tbl_df function.

`glimpse` gives an information dense summary of the data (analagous to `str()`).

`View` (with a capital V) allows you to view the data in a separate tab as a spreadsheet or excel like format 

```{r syntax}
# tbl_df cleans it up
tbl_df(mtcars)

# densely summarizes the data
glimpse(mtcars)
```

---

#### Reshaping Data {.tabset .tabet-fade .tabset-pills}

`gather()` & `spread()` allow you to convert a data frame from wide to tall and vice-versa using a system of key-value pairing.

For the following examples:
`devtools::install_github("garrettgman/DSR")`

```{r load DSR}
# data sets containing WHO documented cases of TB
library(DSR)
```

##### Gather
```{r gather examples}
# cases of TB for 3 countries occurring in 2 separate years 
tbl_df(DSR::table4)

gather(data = table4, key = year, value = cases, columns = 2:3) %>%
  arrange(country)

# population of 3 countries recorded in 2 separate years
tbl_df(table5)

table5 %>% 
  gather(key = year, value = population, -country) %>%
  arrange(desc(population))
```
---

##### Spread

In order for spread to work, each row must have a unique identifier (such as a row index). Otherwise, R won't know how to make proper key-value pair combos in relation to the rest of the variables in your data set.

```{r spread examples}
#population of 219 countries from 1995-2013
glimpse(population)

spread(data = population, key = year, value = population)
```

Here's an example where spread won't work

```{r spread failure, error=TRUE}
scores <- data_frame(id = c(1:6), 
                     group_id = c(1211, 1311, 2634, 1311, 1211, 2634), 
                     exam_1 = c(67, 77, 45, 92, 83, 70),
                     exam_2 = c(85, 76, 69, 94, 88, 80),
                     exam_3 = c(91, 94, 88, 79, 97, 100))

gathered_scores <- scores %>% gather(exam, score, exam_1:exam_3)

tbl_df(gathered_scores)

gathered_scores %>%
  select(-id) %>%
  spread(key = exam, value = score) %>%
  print()
```
---

## Transform {.tabset .tabset-fade .tabset-pills}

Once you have your data in the proper format, you probably want to perform some sort of analysis on it. This is where all the magic happens and dplyr is the package to do it.

### Dplyr {.tabset .tabset-fade.tabset-pills}

dplyr functions take on a SQL like approach to wrangling your data. In conjunction with the %>% (see [Magrittr](#anchor) for more details), R programming becomes much more efficient & intuitive.

#### The Big 5 (Verbs) {.tabset .tabset-fade.tabset-pills}

There are 5 essential data manipulation functions, or verbs, you should know:

* select(), which returns a subset of the columns 
* filter(), that is able to return a subset of the rows 
* arrange(), that reorders the rows according to single or multiple variables 
* mutate(), used to add columns from existing data
* summarise(), which reduces each group to a single row by calculating aggregate measures 

The following examples uses the `flights` dataset from the `nycflights13` package.

```{r nycflights13}
#load the nycflights13 library
library(nycflights13)

#convert profiles dataset into tbl_df (tibble)
#which makes viewing the following examples much easier
flights <- tbl_df(flights)

#have a look at the flights dataset
glimpse(flights)
```

##### Select
You can select particular columns using the name(s) of the column(s), the numerical index of a column or range of columns, excluding particular columns using `-`, or with specific helper functions using in conjunction with the select function.

```{r select}
#use select function to get specified columns
flights %>% select(1:5)

#use names, indexes, and exclusion
flights %>% select(1:6, -5, carrier, origin, dest)

#use helper function 'contains' to select specific columns
flights %>% select(contains("time"))

#use helper function'starts_with' to select specific columns
flights %>% select(starts_with("dep"), ends_with("time"))
```

---

##### Filter

The `filter()` function uses the following logical operators to subset rows of the dataset:  

* `x < y` x is less than y 
* `x <= y` x is less than or equal to y
* `x > y` x is greater than  y
* `x >= y` x is greater than or equal to y
* `x == y` x is equal to y 
* `x != y ` x is not equal to y 
* `x %in% c(y, z)` TRUE if x is in the vector c(y,z)  
* `|` OR operator, i.e. x < y | x > z 
* `&` and operator, i.w. x != 'NA' & x < y 

```{r filter}
#filter for red-eye flights
flights %>% filter(dep_time < 600)

#filter flights by carrier (UA = United Airlines)
flights %>% filter(carrier == 'UA')

#filter flights out of JFK going to SFO and LAX
flights %>% filter(origin == 'JFK' & dest %in% c('SFO', 'LAX'))

#filter flights that left late or arrived ahead of time
flights %>% filter(dep_delay > 0 | arr_delay < 0)
```

---

##### Arrange

Arrange can be used for either ascending order or descending order. The latter requires using the `desc()` function withing the call to `arrange()`
```{r arrange}
#filter by carrier: AA, origin: JFK, and month: June, arrange by flight distance
flights %>% filter(carrier == 'AA' & origin == 'JFK' & month == 6) %>%
  arrange(dest)

#arrange using the desc() function
flights %>% filter(origin != 'JFK' & month > 9) %>%
  arrange(desc(air_time))
```

---

##### Mutate
```{r mutate}
#create a new column : date 
flights %>% mutate(date = as.Date(paste(year,month,day, sep = '-'))) %>%
  select(1:3, date) %>% distinct()

#convert airtime to hours
flights %>% mutate(air_time_hrs = air_time / 60) %>% select(air_time, air_time_hrs)
```

---

##### Summarise
```{r summarise}
#summarise the distance column of the flights dataset
flights %>% summarise(avg_dist = mean(distance),
                      longest_dist = max(distance),
                      shortest_dist = min(distance))
```

---

#### grouping

Another powerful feature of dplyr is grouping. We can define groups within datasets using the `group_by` statement. With these defined groups in place, we can then influence how the summarise function works on the dataset.

```{r}
#find the most visited destination for each carrier, arrange from high to low by count.
flights %>% 
  group_by(carrier, dest) %>% 
  summarise(count = n()) %>%
  filter(count == max(count)) %>%
  arrange(desc(count))

# monthly flight data
flights %>% 
  group_by(month, carrier) %>%
  summarise(total_flights = n(),
            distinct_destinations = n_distinct(dest),
            avg_dep_time = mean(dep_time, na.rm = TRUE),
            longest_flight = max(air_time,  na.rm = TRUE))
```

#### layering

Layering is an important concept to know when it comes to grouping in dplyr. When you summarise data, a grouped layer gets shed each time you call the summarise function. The order of your grouping matters so be careful as the consequences of your order may not be transparent at first.

```{r layering example}
#compute average_air_time per day of each month
average_airtime_per_day <- flights %>%
  group_by(month, day) %>%
  summarise(avg_air_time = mean(air_time, na.rm = TRUE))

#display results
average_airtime_per_day

#compute average air_time per month. The 'day' group gets shed from this layer
average_airtime_per_month <- average_airtime_per_day %>%
  summarise(avg_air_time = mean(avg_air_time))

#display results
average_airtime_per_month

#compute the total average air_time. The 'month' group gets shed leaving a single global mean value for the entire dataset
average_air_time_overall <- average_airtime_per_month %>%
  summarise(avg_air_time = mean(avg_air_time))

#display results
average_air_time_overall
```

---

### PURRR {.tabset .tabset-fade .tabset-pills}

The `purrr` package provides tools for functional programming.

The functions within `purrr` work similarly to the base R `apply` functions

`purrr` is not part of the core tidverse so load it explicitly.

```{r purrr functions}
library(purrr)
```

#### map

The map functions allow you to perform a specific function over multiple arguments.

```{r map}
set.seed(23)

n <- c(1, 5, 10)

rnorm

# map(.x, .f)
map(.x = n, .f = rnorm)


# map2(.x, .y, .f)
means <- c(25, 50, 100)

map2(.x = n, .y = means, .f = rnorm)

#pmap for multiple arguments
sdev <- c(1, 5, 20)

pmap(.l = c(list(n), list(means), list(sdev)), rnorm)
pmap(list(n, means, sdev), rnorm)
```
---

#### invoke

In contrast, say we wanted to apply multiple functions to an argument. The `invoke_map` function can help with that.

```{r invoke}
list_of_functions <- c(rnorm, runif, rexp)
values <- c(1:10)
invoke_map(.f = list_of_functions, 5)

```
---

#### walk

The walk function works similarly to `map` but is used for side effects. 

Side effects are considered to be anything that happens that isn't a return of the function:  
 
* printing output  
* plotting   
* saving files   

```{r walk functions, error=TRUE}
mtcars_subset <- mtcars %>% select(1:3)
titles <- colnames(mtcars)
pwalk(list(mtcars_subset, main = titles), hist, xlab = "")

```
---

#### safely

The `safely` function is very useful for dealing with error.

```{r safely}
df <- data.frame(x = c(1:26),
                 y = letters)
#create function (safe_log) which 'safely' takes the log of a value or vector
safe_log <- safely(log)

safe_log(10)
safe_log("a")

#variable x is all numbers so we should not see any errors
map(df$x, safe_log) %>%
  head()

# variable y contains all errors
map (df, safe_log)

safe_log(df)

```
---

### STRINGR {.tabset .tabset-fade .tabset-pills}

`stringr`, as you may have guessed, is the package for dealing with strings. Stringr works in conjunction with **regular expressions** for pattern matching and recognition.

The `stringr` package needs to be loaded explicitly as it is not part of the CORE tidyerse.

```{r stringr}
library(stringr)

#'fruit', 'sentences, and 'words' are datasets included with the stringr package

some_words <- sample(words, 10)
numbers <- 1:10

some_words
```

#### str concatenate
```{r str_c}
# string concatenate str_c()
map(str_c("word #", numbers,": ", some_words), list)

```
---

#### boundary
```{r stringr boundary}
some_sentences <- sample(sentences, 10)
some_sentences

str_count(string = some_sentences, pattern = boundary("word"))

```
---

#### case sensitive

```{r casing}

some_fruit <- sample(fruit, 10)
some_fruit

caps_fruit <- str_to_upper(some_fruit)
caps_fruit

str_to_lower(caps_fruit)
```
---

#### string split

```{r str_split}
# using some_sentences (see 'boundary' tab)

some_sentences

str_split(string = some_sentences, pattern = boundary("word"))

```
---

# Visualization

GGplot2 is the go to package for visualizing data. The multitude of functions allow for visual flexibility limited only by your imagination. I want to draw your attention to useful functions that you may not know about.

Have you ever tried to plot two variables on the x or y axes using geom_point?


```{r interaction, error = TRUE}
mtcars %>%
  mutate(cyl = factor(cyl),
         gear = factor(gear)) %>%
  ggplot(aes(x = c(gear, cyl), y = mpg)) +
  geom_point()

mtcars %>%
  mutate(cyl = factor(cyl),
         gear = factor(gear)) %>%
  ggplot(aes(x = interaction(cyl, gear, sep = "-"), y = mpg)) +
  geom_point() +
  labs (title = "cyl-gear vs. mpg", x = "Cyl-Gear")
```
---