---
title: "An Introduction to the Tidyverse"
author: "Joseph Walker"
date: "`r Sys.Date()`"
output: 
  html_document: 
    highlight: pygments
    theme: readable
    toc: yes
    toc_float: yes
---
# Introduction

Welcome to the tidyverse tutorial. The information below provides an introduction to the suite of packages contained in the tidyverse that are useful for programming in R. The tidyverse was created by Hadley Wickham, a prominent R developer and statistician. 

Before we begin, here are some useful resources to learn more about R and the topics in this tutorial.

The tidyverse site which contains detailed information about each package: http://tidyverse.org/

The awesome *R for Data Science* book, free and in full: http://r4ds.had.co.nz/

For quick references to useful packages and functions, go to Help --> Cheatsheets in the R studio menu bar. You can also find them here: https://www.rstudio.com/resources/cheatsheets/


```{r setup, include=FALSE, warning = FALSE, message = FALSE}
knitr::opts_chunk$set(echo = TRUE, warning = FALSE, message = FALSE)
```

Let's start by installing the tidyverse:

`install.packages("tidyverse")`

As with all packages, you have to load it before the functions are available to use:

```{r load tidyverse, warning = FALSE, message=TRUE}
library(tidyverse)
```

It is important to note that only the **core** packages are loaded.  Other tidyverse packages need to be loaded explicitly.

We can see all packages that are part of the tidyverse with the following code:

```{r all tidverse packages}
tidyverse_packages(include_self = TRUE)
```

## A Model for Data Analysis

So where to start?

One of the key concepts in R for Data Science is understanding the model used to approach a data science project.  

We can think about this model more broadly to fit the scope of any problem we have or data we seek to analyze:  

![](model.png)  
---
So then, let's dive into the packages as we follow along the steps of our model.

# Import {.tabset .tabset-pills}

In order to work with your data in R, you have to import it!


## readr


* functions tend to be faster (~10x)
* readr functions produce *tibbles* and don't convert character vectors to factors *(more on that later)*
* reproducible: some base R functions inherit behavior from your OS and environment variables and may not work if you share with others

Useful for reading and writing csv, tsv, tables, lines(of a file or string).

```{r readr}

write_csv(x = mtcars, path = "mtcars_data.csv") # writes to current working directory unless otherwise specified in the path argument

read_csv(file = "mtcars_data.csv", col_names = TRUE)
```

---

## readxl

* Must be loaded explicitly  
* Useful for .xls & .xlsx files  

---

## jsonlite

* for pasing json files
* `tidyjson` contains jsonlite functionality and is a useful package that uses 'tidy' principles for turning json data into useful tables.

---

## other types of data

**Haven** for SPSS, Stata and SAS files  
**xml2** for parsing xml  
**rvest** for web scraping  

---

# Data Wrangling

The bread and butter of data analysis involves the next two steps of the model: tidying and transformation, often called **data wrangling**.

## Tidy {.tabset .tabset-fade .tabset-pills #anchor}

Packages in the tidyverse are designed to work together to incorporate *tidy* principles.

There are three rules which make a dataset *tidy*:  

* Each variable must have its own column 
* Each observation must have its own row 
* Each value must have its own cell 

### Forcats {.tabset .tabset-fade .tabset-pills}

If you've ever dealt with factors using base R, you know that it can be a challenge. Thankfully, the `forcats` package has a multitude of functions useful for handling factors efficiently.

**We need to load the `forcats` package explicitly as it is not part of the core tidyverse packages.**

```{r load forcats}
library(forcats)
```

#### Factor Recode
One useful function of `forcats` is `fct_recode`. This allows you to change the levels (or name/identity) of a factor. Here's an example:

```{r change level values}
#Let's use the airquality data set that comes pre-installed in R
glimpse(airquality)

#The month column is data type integer, let's change it to a factor 
airquality$Month <- factor(airquality$Month)

levels(airquality$Month)

#Let's rename the months using the fct_recode function. 
airquality$Month <- fct_recode(airquality$Month, May = '5', June = '6', July = '7', Aug = '8', Sept = '9')
glimpse(airquality$Month)

ggplot(airquality, aes(Month, Temp)) +
  geom_boxplot(aes(fill = Month)) +
  ggtitle(label = "Daily Temperatures Aggregated by Month")
```

---

#### Factor Reverse
If you just want to reverse the order, there's the `fct_rev` function. You can even use it in line when defining your aesthetics in ggplot like so:
```{r reverse the order}

ggplot(airquality, aes(fct_rev(Month), Temp)) +
  geom_boxplot(aes(fill = Month)) +
  labs(x = "Month") +
  ggtitle(label = "Our plot now has the x-axis in reverse order")
```

---

#### Factor Relevel

Another useful function is `fct_relevel`. This function allows us to change any number of levels to any position.

```{r change level position}
airquality$Month <- fct_relevel(airquality$Month, 'Sept', 'July', 'May', 'Aug', 'June')

levels(airquality$Month)

# This may not seem useful at first, but when you need to visualize your data in a particular way, the fct_relevel function is extremely useful...

ggplot(airquality, aes(Month, Temp)) +
  geom_boxplot(aes(fill = Month)) +
  ggtitle(label = "Notice how the order of the level 'Month' has changed")
```

---

#### Factor Reorder

And finally, it is often useful to reorder the factor in a way that is useful for visualization. For this, we can use the `fct_reorder` function.

For this example, let's use the mtcars data set:
```{r fct_reorder setup}
mtcars$model <- row.names(mtcars)

glimpse(mtcars)

mtcars$model <- factor(mtcars$model)

ggplot(mtcars, aes(mpg, model)) +
  geom_point() +
  ggtitle(label = "MPG vs. Car Model")

```

It's difficult to make comparisons when the data is scattered. But we're in luck! We can use the `fct_reorder` function to clean it up.

```{r fct_reorder}
#fct_reorder takes three arguments: f = factor you want to reorder, x = the variable in which the order will be based upon, and optionally fun (a function to  be used if there are multiple values of x for each value of f.) Here we focus on only the first two arguments.

ggplot(mtcars, aes(mpg, fct_reorder(f = model, x = mpg))) +
  geom_point() +
  labs(y = "model") +
  ggtitle(label = "We can make better comparison by reordering the levels based on the mpg values!") +
  theme(plot.title = element_text(size = 10, face = 'bold'))

```

---

### Lubridate

The **Lubridate** package makes working with dates and times a breeze.

Lubrdiate must be loaded explicitly as it is not part of the core tidyverse suite of packages.

```{r load lubridate}
library(lubridate)
```

```{r lubridate}
#today
today()


year <- 2014
month <- 1:12
day <- 1:12

my.dates <- data.frame(year = year,
                   month = month,
                   day = day)

# make_datetime
my.dates$date <- make_datetime(year, month, day)

glimpse(my.dates)

#take dates as strings and convert them to posixct dates using parse_date_time
birthdays <- c("02-23-1955", "09-12-1958", "06-25-1987")

birthdays <- parse_date_time(x = birthdays, orders = "%m-%d-%Y")
lubridate::month(x = birthdays, label = TRUE , abbr = TRUE)

birthdays %>% month(label = TRUE, abbr = FALSE)

ymd(birthdays)

day(birthdays)

#durations
dseconds(60)
dminutes(5)
dhours(c(24, 96))
ddays(3:5)

span <- interval(start = birthdays[1], end = birthdays[3])
span

dur <- as.duration(span)

as.numeric(dur, "days")
```
---

### Magrittr

At the heart of R coding using tidy principles is the piping function **`%>%`**. This useful tools allows you to string together operations in an intuitive way. The piping operator was born from the magrittr package, self described in the vignette as:

> The magrittr (to be pronounced with a sophisticated french accent) is a package with two aims: to decrease development time and to improve readability and maintainability of code. Or even shortr: to make your code smokin' (puff puff)!

The pipe operator, along with many tidyverse functions uses Non-Standard Evaluation (NSE). This concept is essential to the core of R programming. All you need to know about it for now is that it dramatically reduces the amount of typing. 

For more on NSE: https://cran.r-project.org/web/packages/dplyr/vignettes/nse.html

---

### Tibble

A tibble is simply the tidyverse version of a dataframe. It is the strucutural foundation of your data. Tibbles maintain the elements of a dataframe that have stood the test of time and drop those which have proven to be frustrating.

Tibbles: 
* never change an input's type (strings aren't coerced to factors)
* never adjusts the names of variables
* never adds row.names (mtcars example)

```{r tibble example}

"assay value" <- c(2.3, 1.8, 2.1, .7, 1.6)
"y number" <- c("Y29438", "Y22322", "Y27011", "Y16148", "Y21900") 


glimpse(data.frame(`assay value`, `y number`))

glimpse(tibble(`assay value`, `y number`))
glimpse(row.names(tibble(`assay value`, `y number`)))

glimpse(row.names(mtcars))
```

---

### Tidyr {.tabset .tabset-fade .tabset-pills}

**The tidyr package is useful for visualizing and reshaping data.**

#### Nest

Nesting can be performed for many different purposes. One of the most useful I've found is for linear modeling.


```{r nest function}

nested_iris <- iris %>% nest(-Species)
tbl_df(nested_iris)

model <- function(df){lm(Sepal.Length ~ ., data = df)}

nested_iris <- nested_iris %>% 
  mutate(model = map(data, model))

tbl_df(nested_iris)

```
#### Syntax

The following functions are basic but essential to the foundation of the tidyverse.

`tbl_df` makes it easier to take a look at a data frame. R displays only the info. that fits on the screen. By default a tibble utilizes the tbl_df function.

`glimpse` gives an information dense summary of the data (analagous to `str()`).

`View` (with a capital V) allows you to view the data in a separate tab as a spreadsheet or excel like format 

```{r syntax}
# tbl_df cleans it up
tbl_df(mtcars)

# densely summarizes the data
glimpse(mtcars)
```

---

#### Reshaping Data {.tabset .tabet-fade .tabset-pills}

`gather()` & `spread()` allow you to convert a data frame from wide to tall and vice-versa using a system of key-value pairing.

For the following examples:
`devtools::install_github("garrettgman/DSR")`

```{r load DSR}
# data sets containing WHO documented cases of TB
library(DSR)
```

##### Gather
```{r gather examples}
# cases of TB for 3 countries occurring in 2 separate years 
tbl_df(DSR::table4)

gather(data = table4, key = year, value = cases, columns = 2:3) %>%
  arrange(country)

# population of 3 countries recorded in 2 separate years
tbl_df(table5)

table5 %>% 
  gather(key = year, value = population, -country) %>%
  arrange(desc(population))
```
---

##### Spread

In order for spread to work, each row must have a unique identifier (such as a row index). Otherwise, R won't know how to make proper key-value pair combos in relation to the rest of the variables in your data set.

```{r spread examples}
#population of 219 countries from 1995-2013
glimpse(population)

spread(data = population, key = year, value = population)
```

Here's an example where spread won't work

```{r spread failure, error=TRUE}
scores <- data_frame(id = c(1:6), 
                     group_id = c(1211, 1311, 2634, 1311, 1211, 2634), 
                     exam_1 = c(67, 77, 45, 92, 83, 70),
                     exam_2 = c(85, 76, 69, 94, 88, 80),
                     exam_3 = c(91, 94, 88, 79, 97, 100))

gathered_scores <- scores %>% gather(exam, score, exam_1:exam_3)

tbl_df(gathered_scores)

gathered_scores %>%
  select(-id) %>%
  spread(key = exam, value = score) %>%
  print()
```
---

## Transform {.tabset .tabset-fade .tabset-pills}

Once you have your data in the proper format, you probably want to perform some sort of analysis on it. This is where all the magic happens and dplyr is the package to do it.

### Dplyr {.tabset .tabset-fade.tabset-pills}

dplyr functions take on a SQL like approach to wrangling your data. In conjunction with the %>% (see [Magrittr](#anchor) for more details), R programming becomes much more efficient & intuitive.

#### The Big 5 (Verbs)

<<<<<<< HEAD
There are 5 essential data manipulation functions, or verbs, you should know:

* select(), which returns a subset of the columns 
* filter(), that is able to return a subset of the rows 
* arrange(), that reorders the rows according to single or multiple variables 
* mutate(), used to add columns from existing data
* summarise(), which reduces each group to a single row by calculating aggregate measures 
=======
```{r select}
#Following examples use the 'profiles' dataset from the okcupiddata package

#load the library
library(okcupiddata)

#convert profiles dataset into tbl_df (tibble)
#Makes viewing the following examples much easier
profiles <- tbl_df(profiles)

#get column names
names(profiles)

#use select function to get specified columns
select(profiles, 1:6, -5)

#use names rather than indexes
select(profiles, age:education)

#use starts_with() to select certain columns
select(profiles, starts_with("d"), pets, smokes)

#use contains to select specific columns
select(profiles, job, contains("dr"))
```
>>>>>>> refs/remotes/origin/tidyverse-dplyr-select-examples

#### layering

layering is an important concept to know when it comes to grouping in dplyr. When you summarise data, a grouped layer gets shed each time you call the summarise function. Be careful of the consequences as they may not be transparent at first.

```{r layering example}
glimpse(airquality)

mean_temp_by_day <- airquality %>%
  group_by(Month, Day) %>%
  summarise(temp = mean(Temp))

mean_temp_by_day

mean_temp_by_month <- mean_temp_by_day %>%
summarise(temp = mean(temp))

mean_temp_by_month

global.mean <- mean_temp_by_month %>%
  summarise(temp = mean(temp))

global.mean

mean(airquality$Temp)
```



---

### PURRR {.tabset .tabset-fade .tabset-pills}

The `purrr` package provides tools for functional programming.

The functions within `purrr` work similarly to the base R `apply` functions

`purrr` is not part of the core tidverse so load it explicitly.

```{r purrr functions}
library(purrr)
```

#### map

The map functions allow you to perform a specific function over multiple arguments.

```{r map}
set.seed(23)

n <- c(1, 5, 10)

rnorm

# map(.x, .f)
map(.x = n, .f = rnorm)


# map2(.x, .y, .f)
means <- c(25, 50, 100)

map2(.x = n, .y = means, .f = rnorm)

#pmap for multiple arguments
sdev <- c(1, 5, 20)

pmap(.l = c(list(n), list(means), list(sdev)), rnorm)
pmap(list(n, means, sdev), rnorm)
```

#### invoke

In contrast, say we wanted to apply multiple functions to an argument. The `invoke_map` function can help with that.

```{r invoke}
list_of_functions <- c(rnorm, runif, rexp)
values <- c(1:10)
invoke_map(.f = list_of_functions, 5)

```

#### walk

The walk function works similarly to `map` but is used for side effects. 

Side effects are considered to be anything that happens that isn't a return of the function:  
 
* printing output  
* plotting   
* saving files   

```{r walk functions, error=TRUE}
mtcars_subset <- mtcars %>% select(1:3)
titles <- colnames(mtcars)
pwalk(list(mtcars_subset, main = titles), hist, xlab = "")

```

---

#### safely

The `safely` function is very useful for dealing with error.

```{r safely}
df <- data.frame(x = c(1:26),
                 y = letters)
#create function (safe_log) which 'safely' takes the log of a value or vector
safe_log <- safely(log)

safe_log(10)
safe_log("a")

#variable x is all numbers so we should not see any errors
map(df$x, safe_log) %>%
  head()

# variable y contains all errors
map (df, safe_log)

safe_log(df)

```

---

### STRINGR {.tabset .tabset-fade .tabset-pills}

`stringr`, as you may have guessed, is the package for dealing with strings. Stringr works in conjunction with **regular expressions** for pattern matching and recognition.

The `stringr` package needs to be loaded explicitly as it is not part of the CORE tidyerse.

```{r stringr}
library(stringr)

#'fruit', 'sentences, and 'words' are datasets included with the stringr package

some_words <- sample(words, 10)
numbers <- 1:10

some_words
```

#### str concatenate
```{r str_c}
# string concatenate str_c()
map(str_c("word #", numbers,": ", some_words), list)

```

#### boundary
```{r stringr boundary}
some_sentences <- sample(sentences, 10)
some_sentences

str_count(string = some_sentences, pattern = boundary("word"))

```

#### case sensitive

```{r casing}

some_fruit <- sample(fruit, 10)
some_fruit

caps_fruit <- str_to_upper(some_fruit)
caps_fruit

str_to_lower(caps_fruit)
```

#### string split

```{r str_split}
# using some_sentences (see 'boundary' tab)

some_sentences

str_split(string = some_sentences, pattern = boundary("word"))

```

---

# Visualization

GGplot2 is the go to package for visualizing data. The multitude of functions allow for visual flexibility limited only by your imagination. I want to draw your attention to useful functions that you may not know about.

Have you ever tried to plot two variables on the x or y axes using geom_point?


```{r interaction, error = TRUE}
mtcars %>%
  mutate(cyl = factor(cyl),
         gear = factor(gear)) %>%
  ggplot(aes(x = c(gear, cyl), y = mpg)) +
  geom_point()

mtcars %>%
  mutate(cyl = factor(cyl),
         gear = factor(gear)) %>%
  ggplot(aes(x = interaction(cyl, gear, sep = "-"), y = mpg)) +
  geom_point() +
  labs (title = "cyl-gear vs. mpg", x = "Cyl-Gear")
```
